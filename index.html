<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
  /* Design Credits: Arnav Jain, Nilesh Gupta, Aditya Kusupati, Jon Barron, Deepak Pathak and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f5b461;
  text-decoration:none;
  }
  body,td,th {
     font-family: 'Source Sans Pro', Arial, sans-serif;
     font-size: 16px;
     font-weight: 400
  }
  heading {
     font-family: 'Source Sans Pro', Arial, sans-serif;
     font-size: 19px;
     font-weight: 600
  }
  strong {
     font-family: 'Source Sans Pro', Arial, sans-serif;
     font-size: 16px;
     font-weight: 800
  }
  strongred {
     font-family: 'Source Sans Pro', Arial, sans-serif;
     color: 'red' ;
     font-size: 16px
  }
  sectionheading {
     font-family: 'Source Sans Pro', Arial, sans-serif;
     font-size: 22px;
     font-weight: 600
  }
  pageheading {
     font-family: 'Source Sans Pro', Arial, sans-serif;
     font-size: 60px;
     font-weight: 400
  }
  </style>
  <!-- <link rel="icon" type="image/png" href="images/W.png"> -->
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Arnav Kumar Jain</title>
  <link rel = "icon" href = "images/profile_pic.png" type = "image/x-icon">
  <meta name="Arnav Jain's Homepage" http-equiv="Content-Type" content="Arnav Jain's Homepage">
  <!-- link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'> -->
  <link href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:wght@200;300;400;600;700&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=PT+Sans:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <script type="text/javascript" src="js/toggle.js"></script>
  <!-- Start : Google Analytics Code -->
  <!-- <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90394621-1', 'auto');
  ga('send', 'pageview');

  </script> -->
  <!-- End : Google Analytics Code -->
  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
</head>

<body>
<table width="840" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
<tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
	<p align="left">
		<center><pageheading>Arnav Kumar Jain</pageheading><br>
		<b>&nbsp;Email</b>: <a href="mailto:arnavkj95@gmail.com">arnavkj95@gmail.com</a></center>
	</p>

	<tr>
		<td width="32%" valign="top"><a href="#Bio">
			<img src="images/me.jpg" width="100%" style="border-radius:15px"></a>
			<p align=center>
				<a href="resources/CV.pdf" target="_blank">CV</a> | <a href="https://scholar.google.com/citations?hl=en&user=tu7wKckAAAAJ" target="_blank">Scholar</a> | <a href="https://github.com/arnavkj1995" target="_blank">Github</a> | <a href="https://twitter.com/arnavkj95" target="_blank">Twitter</a>
			</p>
		</td>

		<td width="68%" valign="top" align="justify" id="Bio">
			I am first year Ph.D. student at <a href="https://www.umontreal.ca/" target="_blank">Université de Montréal</a> and <a href="https://mila.quebec/" target="_blank">Mila</a> under the supervision of <a href="https://mila.quebec/en/person/irina-rish/" target="_blank">Prof. Irina Rish</a>. I am passionate about building agents that can efficiently explore the world and generalize to unseen tasks.
      <br><br>
      Previously, I was a Data & Applied Scientist at Microsoft, working on web-scale algorithms for ads recommendation. I was fortunate enough to collaborate with <a href="http://manikvarma.org/" target="_blank">Dr. Manik Varma</a> at Microsoft Research, India and worked on applications of Extreme Classification.
      <br><br>
      Before that, I earned my Integrated M.Sc. in Mathematics and Computing from <a href="http://www.iitkgp.ac.in/" target="_blank">Indian Institute of Technology Kharagpur</a>, where I had the pleasure of working with <a href="https://cse.iitkgp.ac.in/~pabitra/">Prof. Pabitra Mitra</a>, <a href="http://www.facweb.iitkgp.ac.in/~jay/">Prof. Jayanta MukhoPadhyay</a> and <a href="http://www.iitkgp.ac.in/department/EC/faculty/ec-pkb">Prof. Prabir Kumar Biswas</a>. I also spent time in <a href="http://krssg.in/">KRSSG</a> working on path planning algorithms for autonomous soccer playing robots. 
		</td>
	</tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
	<tr><td id="Publications"> <sectionheading>&nbsp;&nbsp;Publications</sectionheading><div style="float: right;"></div></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
		<td width="33%" valign="top" align="center"><a href="pubs/Saini21.pdf" target="_blank"><img src="images/Saini21.jpg" alt="GalaXC" width="100%" style="border-radius:1px"></a></td>
		<td width="67%" valign="top">
			<p>
        <a href="pubs/Saini21.pdf" target="_blank" id="GalaXC">
				<heading>GalaXC: Graph Neural Networks with Labelwise Attention for Extreme Classification</heading></a><br>
				<a href="http://deepaksaini119.github.io/" target="_blank">Deepak Saini</a>*, <strong>Arnav Kumar Jain</strong>*, Kushal Dave*, Jian Jiao, Amit Singh, Ruofei Zhang and <a href="http://manikvarma.org" target="_blank">Manik Varma</a><br>
				The Web Conference (<b>TheWebConf</b>), 2021<br>
			</p>
			<!-- Long Oral presentation<br> -->
			<div class="paper" id="Saini21">
				<a href="javascript:toggleblock('Saini21abs')">abstract</a> /
				<a shape="rect" href="javascript:togglebib('Saini21')" class="togglebib">bibtex</a> /
				<a href="pubs/Saini21.pdf" target="_blank">pdf</a> /
				<a href="https://github.com/Extreme-classification/GalaXC" target="_blank">code</a>
				<br>
				<p align="justify" > <i id="Saini21abs">This paper develops the GalaXC algorithm for Extreme Classification, where the task is to annotate a document with the most relevant subset of labels from an extremely large label set. Extreme classification has been successfully applied to several real world web-scale applications such as web search, product recommendation, query rewriting, etc. GalaXC identifies two critical deficiencies in leading extreme classification algorithms. First, existing approaches generally assume that documents and labels reside in disjoint sets, even though in several applications, labels and documents cohabit the same space. Second, several approaches, albeit scalable, do not utilize various forms of metadata offered by applications, such as label text and label correlations. To remedy these, GalaXC presents a framework that enables collaborative learning over joint document-label graphs at massive scales, in a way that naturally allows various auxiliary sources of information, including label metadata, to be incorporated. GalaXC also introduces a novel label-wise attention mechanism to meld high-capacity extreme classifiers with its framework. An efficient end-to-end implementation of GalaXC is presented that could be trained on a dataset with 50M labels and 97M training documents in less than 100 hours on 4xV100 GPUs. This allowed GalaXC to not only scale to applications with several millions of labels, but also be up to 18% more accurate than leading deep extreme classifiers, while being upto 2-50x faster to train and 10x faster to predict on benchmark datasets. GalaXC is particularly well-suited to warm-start scenarios where predictions need to be made on data points with partially revealed label sets, and was found to be up to 25% more accurate than extreme classification algorithms specifically designed for warm start settings. In A/B tests conducted on the Bing search engine, GalaXC could improve the Click Yield (CY) and coverage by 1.52% and 1.11% respectively. Code for GalaXC is available at <a href="https://github.com/Extreme-classification/GalaXC">https://github.com/Extreme-classification/GalaXC</a>.</i></p>

        <pre xml:space="preserve">
@InProceedings{Saini21,
  author    = "Saini, D. and Jain, A.~K. and Dave, K. and
    Jiao, J. and Singh, A. and Zhang, R. and Varma, M.",
  title     = "GalaXC: Graph neural networks with 
    labelwise attention for extreme classification",
  booktitle = "Proceedings of The ACM International 
    World Wide Web Conference",
  month     = "April",
  year      = "2021",
}
          </pre>
	      </div>
     	</td>
  	</tr>
    <tr>
    <td width="33%" valign="top" align="center"><a href="pubs/Lahiri20.pdf" target="_blank"><img src="images/Lahiri20.gif" alt="PriorGAN" width="100%" style="border-radius:1px"></a></td>
    <td width="67%" valign="top">
      <p>
        <a href="pubs/Lahiri20.pdf" target="_blank" id="PriorGAN">
        <heading>Prior Guided GAN Based Semantic Inpainting</heading></a><br>
        <a href="https://sites.google.com/site/aviseklahiri/home" target="_blank">Avisek Lahiri*</a>, <strong>Arnav Kumar Jain</strong>*, Sanskar Agrawal, <a href="https://cse.iitkgp.ac.in/~pabitra/" target="_blank">Pabitra Mitra</a>, and <a href="http://www.iitkgp.ac.in/department/EC/faculty/ec-pkb" target="_blank">Prabir Kumar Biswas</a> <br>
        Computer Vision and Patten Recognition (<b>CVPR</b>), 2020<br>
      </p>
      <!-- Long Oral presentation<br> -->
      <div class="paper" id="lahiri2020prior">
        <a href="javascript:toggleblock('Lahiri20abs')">abstract</a> /
        <a shape="rect" href="javascript:togglebib('lahiri2020prior')" class="togglebib">bibtex</a> /
        <a href="pubs/Lahiri20.pdf" target="_blank">pdf</a> /
        <a href="resources/Lahiri20slides.pdf" target="_blank">slides</a>
        <br>
        <p align="justify" > <i id="Lahiri20abs">Contemporary deep learning based semantic inpainting can be approached from two directions. First, and the more explored,  approach is to train an offline deep regression network over the masked pixels with an additional refinement by adversarial training. This approach requires a single feed-forward pass for inpainting at inference. Another promising, yet unexplored approach is to first train a generative model to map a latent prior distribution to natural image manifold and during inference time search for the `best-matching' prior to reconstruct the signal. The primary aversion towards the latter genre is due to its inference time iterative optimization and difficulty to scale to higher resolution. In this paper, going against the general trend, we focus on the second paradigm of inpainting and address both of its mentioned problems. Most importantly, we learn a data driven parametric network to directly predict a matching prior for a given masked image. This converts an iterative paradigm to a single feed forward inference pipeline with around 800x speedup.  We also regularize our network with structural prior (computed from the masked image itself) which helps in better preservation of pose and size of the object to be inpainted. Moreover, to extend our model for sequence reconstruction, we propose a recurrent net based grouped latent prior learning. Finally, we leverage recent advancements in high resolution GAN training to scale our inpainting network to 256x256. Experiments (spanning across resolutions from 64x64 to 256x256) conducted on SVHN, Standford Cars, CelebA, CelebA-HQ and ImageNet image datasets, and FaceForensics video datasets reveal that we consistently improve upon contemporary benchmarks from both schools of approaches.</a>.</i></p>
        <pre xml:space="preserve">
@inproceedings{lahiri2020prior,
  title     = {Prior Guided GAN Based Semantic Inpainting},
  author    = {Lahiri, Avisek and Jain, Arnav Kumar and Agrawal, 
    Sanskar and Mitra, Pabitra and Biswas, Prabir Kumar},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer 
    Vision and Pattern Recognition},
  pages     = {13696--13705},
  year      = {2020}
}
          </pre>
        </div>
      </td>
    </tr>
    <tr>
    <td width="33%" valign="top" align="center"><a href="pubs/Lahiri19.pdf" target="_blank"><img src="images/Lahiri19.png" alt="SemanticGAN" width="100%" style="border-radius:1px"></a></td>
    <td width="67%" valign="top">
      <p>
        <a href="pubs/Lahiri19.pdf" target="_blank" id="SemanicGAN">
        <heading>Faster unsupervised semantic inpainting: A GAN based approach</heading></a><br>
        <a href="https://sites.google.com/site/aviseklahiri/home" target="_blank">Avisek Lahiri*</a>, <strong>Arnav Kumar Jain</strong>*, Divyasri Nadendla, and <a href="http://www.iitkgp.ac.in/department/EC/faculty/ec-pkb" target="_blank">Prabir Kumar Biswas</a> <br>
        Computer Vision and Patten Recognition (<b>ICIP</b>), 2019 <br>
      </p>
      <!-- Long Oral presentation<br> -->
      <div class="paper" id="lahiri2019prior">
        <a href="javascript:toggleblock('Lahiri19abs')">abstract</a> /
        <a shape="rect" href="javascript:togglebib('lahiri2019prior')" class="togglebib">bibtex</a> /
        <a href="pubs/Lahiri19.pdf" target="_blank">pdf</a>
        <br>
        <p align="justify" > <i id="Lahiri19abs">In this paper, we propose to improve the inference speed and visual quality of contemporary baseline of Generative Adversarial Networks (GAN) based unsupervised semantic inpainting. This is made possible with better initialization of the core iterative optimization involved in the framework. To our best knowledge, this is also the first attempt of GAN based video inpainting with consideration to temporal cues. On single image inpainting, we achieve about 4.5-5x speedup and 80x on videos compared to baseline. Simultaneously, our method has better spatial and temporal reconstruction qualities as found on three image and one video dataset.</a>.</i></p>
        <pre xml:space="preserve">
@inproceedings{lahiri2019faster,
  title        = {Faster Unsupervised Semantic Inpainting: 
    A GAN Based Approach},
  author       ={Lahiri, Avisek and Jain, Arnav Kumar and Nadendla, 
    Divyasri and Biswas, Prabir Kumar},
  booktitle    = {2019 IEEE International Conference on Image 
    Processing (ICIP)},
  pages        = {2706--2710},
  year         = {2019},
  organization = {IEEE}
}
          </pre>
        </div>
      </td>
    </tr>

        <tr>
    <td width="33%" valign="top" align="center"><a href="pubs/Agarwalla18.pdf" target="_blank"><img src="images/Agarwalla18.png" alt="KRSSG" width="100%" style="border-radius:1px"></a></td>
    <td width="67%" valign="top">
      <p>
        <a href="pubs/Agarwalla18.pdf" target="_blank" id="KRSSG">
        <heading>Bayesian Optimisation with Prior Reuse for Motion Planning in Robot Soccer</heading></a><br>
        <a href="https://abhinavagarwalla.github.io/" target="_blank">Abhinav Agarwalla*</a>, <strong>Arnav Kumar Jain</strong>*, <a href="https://kvmanohar22.github.io/" target="_blank">KV Manohar</a>, Arpit Tarang Saxena, and <a href="http://www.facweb.iitkgp.ac.in/~jay/" target="_blank">Jayanta Mukhopadhyay</a> <br>
        Conference on Data Science and Management of Data (<b>CoDS-COMAD</b>), 2018 <br>
      </p>
      <!-- Long Oral presentation<br> -->
      <div class="paper" id="agarwalla2018bayesian">
        <a href="javascript:toggleblock('Agarwalla18abs')">abstract</a> /
        <a shape="rect" href="javascript:togglebib('agarwalla2018bayesian')" class="togglebib">bibtex</a> /
        <a href="pubs/Agarwalla18.pdf" target="_blank">pdf</a>
        <br>
        <p align="justify" > <i id="Agarwalla18abs">We integrate learning and motion planning for soccer playing differential drive robots using Bayesian optimisation. Trajectories generated using end-slope cubic Bézier splines are first optimised globally through Bayesian optimisation for a set of candidate points with obstacles. The optimised trajectories along with robot and obstacle positions and velocities are stored in a database. The closest planning situation is identified from the database using k-Nearest Neighbour approach. It is further optimised online through reuse of prior information from previously optimised trajectory. Our approach reduces computation time of trajectory optimisation considerably. Velocity profiling generates velocities consistent with robot kinodynamoic constraints, and avoids collision and slipping. Extensive testing is done on developed simulator as well as on physical differential drive robots. Our method shows marked improvements in mitigating tracking error, and reducing traversal and computational time over competing techniques under the constraints of performing tasks in real time.</a>.</i></p>
        <pre xml:space="preserve">
@inproceedings{agarwalla2018bayesian,
  title     = {Bayesian optimisation with prior reuse 
    for motion planning in robot soccer},
  author    = {Agarwalla, Abhinav and Jain, Arnav Kumar 
    and Manohar, KV and Saxena, Arpit Tarang and 
    Mukhopadhyay, Jayanta},
  booktitle = {Proceedings of the ACM India Joint 
    International Conference on Data Science and 
    Management of Data},
  pages     = {88--97},
  year      = {2018}
}

          </pre>
        </div>
      </td>
    </tr>

        <tr>
    <td width="33%" valign="top" align="center"><a href="pubs/Jain17.pdf" target="_blank"><img src="images/Jain17.jpg" alt="RecurrentMemory" width="100%" style="border-radius:1px"></a></td>
    <td width="67%" valign="top">
      <p>
        <a href="pubs/Jain17.pdf" target="_blank" id="RecurrentMemory">
        <heading>Recurrent Memory Addressing for describing videos</heading></a><br>
        <strong>Arnav Kumar Jain</strong>*, <a href="https://abhinavagarwalla.github.io/" target="_blank">Abhinav Agarwalla*</a>, <a href="https://people.eecs.berkeley.edu/~krishna/" target="_blank">Kumar Krishna Agrawal*</a>, and <a href="https://cse.iitkgp.ac.in/~pabitra/" target="_blank">Pabitra Mitra</a> <br>
        Deep Vision Workshop at Computer Vision and Pattern Recognition (<b>CVPRW</b>), 2017 <br>
      </p>
      <!-- Long Oral presentation<br> -->
      <div class="paper" id="jain2017recurrent">
        <a href="javascript:toggleblock('Jain17abs')">abstract</a> /
        <a shape="rect" href="javascript:togglebib('jain2017recurrent')" class="togglebib">bibtex</a> /
        <a href="pubs/Jain17.pdf" target="_blank">pdf</a>
        <br>
        <p align="justify" > <i id="Jain17abs">Deep Neural Network architectures with external memory components allow the model to perform inference and capture long term dependencies by storing information explicitly. In this paper, we generalize Key-Value Memory Networks to a multimodal setting and introduce a novel key-addressing mechanism to deal with sequence-to-sequence models. <br>The advantages of the framework are demonstrated on the task of generating natural language descriptions for videos. The proposed model naturally decomposes the problem of video captioning into vision and language segments, dealing with them as key-value pairs. More specifically, we learn a semantic embedding (v) corresponding to each keyframe (k) in the video, thereby creating (k, v) memory slots. We propose to find the attention weights, conditioned on the previous attention distributions for the key-value memory slots in the memory addressing schema. Exploiting this flexibility of the framework, we capture spatial dependencies while mapping from the visual to semantic embedding. Experiments done on the Youtube2Text dataset demonstrate usefulness of this recurrent key-addressing, while achieving competitive scores on BLEU@4, METEOR metrics against state-of-the-art models.</a>.</i></p>
        <pre xml:space="preserve">
@inproceedings{jain2017recurrent,
  title     = {Recurrent Memory Addressing for Describing Videos.},
  author    = {Jain, Arnav Kumar and Agarwalla, Abhinav and 
    Agrawal, Kumar Krishna and Mitra, Pabitra},
  booktitle = {CVPR Workshops},
  volume    = {7},
  year      = {2017}
}
          </pre>
        </div>
      </td>
    </tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
     <tr><td><br><p align="right"><font size="2">
     Template: <a href="https://nilesh2797.github.io">this</a>,
     <a href="https://jonbarron.info">this</a>, <a href="https://people.eecs.berkeley.edu/~pathak/">this</a> and <a href="https://homes.cs.washington.edu/~kusupati//">this</a>
     </font></p></td></tr>
</table>

</td></tr>
</table>

<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('Saini21abs');
</script>
<script xml:space="preserve" language="JavaScript">
    hideblock('Lahiri20abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('Lahiri19abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('Agarwalla18abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('Jain17abs');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('acknowledgements');
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('gradschool');
</script>
<script xml:space="preserve" language="JavaScript">
hideblock('quotes');
</script>

</body>

</html>
